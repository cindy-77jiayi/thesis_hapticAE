{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1",
      "metadata": {},
      "source": [
        "# Haptic Signal VAE — Colab Training\n",
        "\n",
        "This notebook runs the full training pipeline on Google Colab.\n",
        "\n",
        "**Data source:** Cloned directly from [HapticGen/hapticgen-dataset](https://github.com/HapticGen/hapticgen-dataset) — no Google Drive needed for data.\n",
        "\n",
        "**Steps:**\n",
        "1. Clone code repo + dataset repo from GitHub\n",
        "2. Install dependencies\n",
        "3. Run training\n",
        "4. Evaluate and listen to results\n",
        "5. (Optional) Save outputs to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Clone code repo (or pull latest)\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/cindy-77jiayi/thesis_hapticAE.git\"\n",
        "REPO_DIR = \"/content/thesis_hapticAE\"\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    !cd {REPO_DIR} && git pull\n",
        "else:\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Clone dataset directly from GitHub (no Google Drive needed)\n",
        "DATASET_URL = \"https://github.com/HapticGen/hapticgen-dataset.git\"\n",
        "DATASET_DIR = \"/content/hapticgen-dataset\"\n",
        "\n",
        "if os.path.exists(DATASET_DIR):\n",
        "    !cd {DATASET_DIR} && git pull\n",
        "else:\n",
        "    !git clone {DATASET_URL} {DATASET_DIR}\n",
        "\n",
        "# Data path for training\n",
        "DATA_DIR = os.path.join(DATASET_DIR, \"expertvoted\")\n",
        "print(f\"Dataset: {DATA_DIR}\")\n",
        "print(f\"Files: {len(os.listdir(DATA_DIR)) if os.path.exists(DATA_DIR) else 'NOT FOUND'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Install dependencies\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Configure paths\n",
        "OUTPUT_DIR = \"/content/outputs\"  # Colab local storage (fast)\n",
        "CONFIG = \"configs/vae_default.yaml\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data:   {DATA_DIR}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "print(f\"Config: {CONFIG}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Run training\n",
        "!python scripts/train.py --config {CONFIG} --data_dir {DATA_DIR} --output_dir {OUTPUT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Evaluate: load results and visualize\n",
        "import os, sys, glob\n",
        "\n",
        "# Ensure repo is on Python path\n",
        "REPO_DIR = \"/content/thesis_hapticAE\"\n",
        "os.chdir(REPO_DIR)\n",
        "if REPO_DIR not in sys.path:\n",
        "    sys.path.insert(0, REPO_DIR)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.utils.config import load_config\n",
        "from src.utils.seed import set_seed\n",
        "from src.data.preprocessing import collect_clean_wavs, estimate_global_rms\n",
        "from src.data.dataset import HapticWavDataset\n",
        "from src.models.conv_vae import ConvVAE\n",
        "from src.eval.evaluate import evaluate_reconstruction, print_metrics\n",
        "from src.eval.visualize import plot_loss_curves, plot_waveform_comparison\n",
        "from src.eval.audio import play_ab_comparison\n",
        "\n",
        "CONFIG = \"configs/vae_default.yaml\"\n",
        "OUTPUT_DIR = \"/content/outputs\"\n",
        "DATA_DIR = \"/content/hapticgen-dataset/expertvoted\"\n",
        "\n",
        "config = load_config(CONFIG)\n",
        "set_seed(config['seed'])\n",
        "\n",
        "# Find latest run\n",
        "run_dirs = sorted(glob.glob(f\"{OUTPUT_DIR}/*/best_model.pt\"))\n",
        "assert run_dirs, \"No trained models found\"\n",
        "ckpt_path = run_dirs[-1]\n",
        "run_dir = os.path.dirname(ckpt_path)\n",
        "print(f\"Using checkpoint: {ckpt_path}\")\n",
        "\n",
        "# Load metrics\n",
        "metrics = np.load(os.path.join(run_dir, 'metrics.npz'))\n",
        "plot_loss_curves(metrics['train_losses'].tolist(), metrics['val_losses'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Reconstruction evaluation + audio\n",
        "data_cfg = config['data']\n",
        "wav_files = collect_clean_wavs(DATA_DIR)\n",
        "N = len(wav_files)\n",
        "perm = np.random.permutation(N)\n",
        "split = int(data_cfg['train_split'] * N)\n",
        "val_files = [wav_files[i] for i in perm[split:]]\n",
        "train_files = [wav_files[i] for i in perm[:split]]\n",
        "global_rms = estimate_global_rms(train_files, n=200, sr_expect=data_cfg['sr'])\n",
        "\n",
        "val_ds = HapticWavDataset(val_files, T=data_cfg['T'], sr_expect=data_cfg['sr'], global_rms=global_rms, scale=data_cfg['scale'])\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_cfg = config['model']\n",
        "model = ConvVAE(\n",
        "    T=data_cfg['T'], latent_dim=model_cfg['latent_dim'],\n",
        "    channels=tuple(model_cfg['channels']),\n",
        "    first_kernel=model_cfg.get('first_kernel', 25),\n",
        "    kernel_size=model_cfg.get('kernel_size', 9),\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "result = evaluate_reconstruction(model, val_loader, device, n_samples=10)\n",
        "print_metrics(result)\n",
        "plot_waveform_comparison(result['x_np'], result['xhat_np'])\n",
        "play_ab_comparison(result['x_np'], result['xhat_np'], sr=data_cfg['sr'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0",
      "metadata": {},
      "source": [
        "---\n",
        "## PCA Control Pipeline\n",
        "\n",
        "Extract latent vectors from the full dataset, fit PCA to get 8 interpretable control dimensions, and run sweep experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Extract latent vectors + fit PCA\n",
        "PCA_DIR = \"/content/outputs/pca\"\n",
        "\n",
        "!python scripts/extract_and_pca.py \\\n",
        "    --config {CONFIG} \\\n",
        "    --data_dir {DATA_DIR} \\\n",
        "    --checkpoint {ckpt_path} \\\n",
        "    --output_dir {PCA_DIR} \\\n",
        "    --n_components 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Single-axis sweep: visualize what each PC controls\n",
        "import pickle\n",
        "from src.pipelines.pca_control import single_axis_sweep, plot_sweep, play_sweep\n",
        "\n",
        "with open(f\"{PCA_DIR}/pca_pipe.pkl\", \"rb\") as f:\n",
        "    pipe = pickle.load(f)\n",
        "\n",
        "# Sweep PC1 through PC4 (most important axes)\n",
        "for ax in range(4):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Sweeping PC{ax+1} from -2 to +2\")\n",
        "    print(f\"{'='*60}\")\n",
        "    result = single_axis_sweep(\n",
        "        pipe, model, device,\n",
        "        axis=ax, sweep_range=(-2.0, 2.0), n_steps=9,\n",
        "        T=data_cfg['T'],\n",
        "    )\n",
        "    plot_sweep(result, sr=data_cfg['sr'])\n",
        "    play_sweep(result, sr=data_cfg['sr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Inspect PCA: variance explained and control space statistics\n",
        "Z = np.load(f\"{PCA_DIR}/Z.npy\")\n",
        "Z_pca = np.load(f\"{PCA_DIR}/Z_pca.npy\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Full PCA to see variance dropoff\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "Z_scaled = StandardScaler().fit_transform(Z)\n",
        "full_pca = PCA().fit(Z_scaled)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# Scree plot\n",
        "ax1.bar(range(1, len(full_pca.explained_variance_ratio_)+1), full_pca.explained_variance_ratio_)\n",
        "ax1.axvline(x=8.5, color='r', linestyle='--', label='8 components')\n",
        "ax1.set_xlabel('Principal Component')\n",
        "ax1.set_ylabel('Explained Variance Ratio')\n",
        "ax1.set_title('Scree Plot')\n",
        "ax1.legend()\n",
        "\n",
        "# Cumulative variance\n",
        "cumvar = np.cumsum(full_pca.explained_variance_ratio_)\n",
        "ax2.plot(range(1, len(cumvar)+1), cumvar, 'o-')\n",
        "ax2.axhline(y=0.9, color='r', linestyle='--', label='90% threshold')\n",
        "ax2.axvline(x=8, color='g', linestyle='--', label='8 components')\n",
        "ax2.set_xlabel('Number of Components')\n",
        "ax2.set_ylabel('Cumulative Explained Variance')\n",
        "ax2.set_title('Cumulative Variance Explained')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nVariance explained by 8 PCs: {cumvar[7]:.2%}\")\n",
        "print(f\"Variance explained by 16 PCs: {cumvar[15]:.2%}\")\n",
        "print(f\"Components needed for 90%: {np.argmax(cumvar >= 0.9) + 1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9",
      "metadata": {},
      "source": [
        "---\n",
        "## (Optional) Save outputs to Google Drive\n",
        "\n",
        "Colab local storage is wiped when the session ends. Run the cell below to copy your trained model and PCA results to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: save outputs to Google Drive for persistence\n",
        "SAVE_TO_DRIVE = False  # Set to True if you want to save\n",
        "\n",
        "if SAVE_TO_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_OUTPUT = \"/content/drive/MyDrive/thesis/outputs\"\n",
        "    os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
        "    !cp -r {OUTPUT_DIR}/* {DRIVE_OUTPUT}/\n",
        "    print(f\"Saved to: {DRIVE_OUTPUT}\")\n",
        "else:\n",
        "    print(\"Skipped. Set SAVE_TO_DRIVE = True to save to Google Drive.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
